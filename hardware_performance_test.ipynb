{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hardware Performance Testing\n",
    "\n",
    "Test TinyMPC hardware performance by measuring execution time as a function of max_iter for different bitstreams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "# Add driver path\n",
    "os.chdir(\"/home/xilinx/jupyter_notebooks/zhenyu/tinympc_ip_gen/\")\n",
    "\n",
    "sys.path.append('driver')\n",
    "from tinympc_hw import tinympc_hw\n",
    "\n",
    "# Import dynamics for test problem setup\n",
    "from dynamics import LinearizedQuadcopterDynamics, CrazyflieParams, NoiseModel\n",
    "\n",
    "print(\"All modules imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dynamics model for test problem\n",
    "params = CrazyflieParams()\n",
    "noise_model = NoiseModel()\n",
    "dynamics = LinearizedQuadcopterDynamics(params, noise_model)\n",
    "\n",
    "# Generate system matrices\n",
    "control_freq = 100.0  # Hz\n",
    "A, B = dynamics.generate_system_matrices(control_freq)\n",
    "Q, R = dynamics.generate_cost_matrices()\n",
    "constraints = dynamics.generate_constraints()\n",
    "\n",
    "# System dimensions (fixed for quadrotor)\n",
    "nx = 12  # State dimension\n",
    "nu = 4   # Control dimension\n",
    "\n",
    "print(f\"Test problem configured:\")\n",
    "print(f\"  State dimension (nx): {nx}\")\n",
    "print(f\"  Control dimension (nu): {nu}\")\n",
    "print(f\"  Note: Prediction horizon (N) will be extracted from each bitstream\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate test data\n",
    "def generate_test_data(nx, nu, N):\n",
    "    \"\"\"Generate random test data for MPC problem\"\"\"\n",
    "    np.random.seed(42)  # For reproducibility\n",
    "    \n",
    "    # Initial state with some deviation from origin\n",
    "    x0 = np.random.randn(nx) * 0.1\n",
    "    x0[2] = 1.0  # Set altitude to 1m\n",
    "    \n",
    "    # Reference trajectory (hover at origin)\n",
    "    xref = np.zeros((N, nx))\n",
    "    xref[:, 2] = 1.0  # Reference altitude\n",
    "    \n",
    "    # Reference control (hover)\n",
    "    uref = np.zeros((N-1, nu))\n",
    "    \n",
    "    return x0, xref, uref\n",
    "\n",
    "def extract_N_from_bitstream(bitstream_path):\n",
    "    \"\"\"Extract N parameter from bitstream filename\"\"\"\n",
    "    import re\n",
    "    filename = bitstream_path.name if hasattr(bitstream_path, 'name') else str(bitstream_path)\n",
    "    pattern = r'tinympcproj_N(\\d+)_'\n",
    "    match = re.search(pattern, filename)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    else:\n",
    "        print(f\"Warning: Could not extract N from {filename}, using default N=5\")\n",
    "        return 5\n",
    "\n",
    "# Note: Test data will be generated per bitstream with correct N\n",
    "print(\"Test data generation functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all bitstream files in subdirectories\n",
    "import os\n",
    "from pathlib import Path\n",
    "import glob\n",
    "\n",
    "def find_all_bitstreams(base_path=\".\"):\n",
    "    \"\"\"Find all .bit files in the project directory and subdirectories\"\"\"\n",
    "    bitstream_files = []\n",
    "    \n",
    "    # Search for .bit files recursively\n",
    "    search_pattern = os.path.join(base_path, \"**\", \"*.bit\")\n",
    "    found_files = glob.glob(search_pattern, recursive=True)\n",
    "    \n",
    "    # Convert to Path objects and filter out any invalid paths\n",
    "    for file_path in found_files:\n",
    "        path_obj = Path(file_path)\n",
    "        if path_obj.exists() and path_obj.is_file():\n",
    "            bitstream_files.append(path_obj)\n",
    "    \n",
    "    # Also check specific known locations\n",
    "    known_dirs = [\"bitstream\", \"impl\", \"output\", \"build\"]\n",
    "    for dir_name in known_dirs:\n",
    "        dir_path = Path(base_path) / dir_name\n",
    "        if dir_path.exists() and dir_path.is_dir():\n",
    "            bit_files = list(dir_path.glob(\"*.bit\"))\n",
    "            for bit_file in bit_files:\n",
    "                if bit_file not in bitstream_files:\n",
    "                    bitstream_files.append(bit_file)\n",
    "    \n",
    "    return sorted(bitstream_files)\n",
    "\n",
    "def test_bitstream_performance(bitstream_path, test_maxiter_values=[10, 100, 1000], num_trials=10):\n",
    "    \"\"\"\n",
    "    Test a bitstream with specific max_iter values, with warmup run\n",
    "    \n",
    "    Args:\n",
    "        bitstream_path: Path to bitstream file\n",
    "        test_maxiter_values: List of max_iter values to test (default: [10, 100, 1000])\n",
    "        num_trials: Number of trials per max_iter value (excluding warmup)\n",
    "    \n",
    "    Returns:\n",
    "        dict: Results with average execution times\n",
    "    \"\"\"\n",
    "    # Extract N from bitstream filename\n",
    "    N = extract_N_from_bitstream(bitstream_path)\n",
    "    \n",
    "    # Generate test data with correct dimensions\n",
    "    nx = 12  # State dimension (fixed for quadrotor)\n",
    "    nu = 4   # Control dimension (fixed for quadrotor)\n",
    "    x0_test, xref_test, uref_test = generate_test_data(nx, nu, N)\n",
    "    \n",
    "    # Initialize hardware solver\n",
    "    hw_solver = tinympc_hw(bitstream_path=str(bitstream_path))\n",
    "    \n",
    "    results = {\n",
    "        'bitstream': str(bitstream_path),\n",
    "        'N': N,\n",
    "        'maxiter_values': test_maxiter_values,\n",
    "        'avg_times': {},\n",
    "        'all_times': {}\n",
    "    }\n",
    "    \n",
    "    for max_iter in test_maxiter_values:\n",
    "        # Set check_termination equal to max_iter as requested\n",
    "        check_termination = max_iter\n",
    "        hw_solver.setup(max_iter=max_iter, check_termination=check_termination, verbose=0)\n",
    "        \n",
    "        # Warmup run (first run to prepare hardware)\n",
    "        hw_solver.set_x0(x0_test)\n",
    "        hw_solver.set_x_ref(xref_test)\n",
    "        hw_solver.set_u_ref(uref_test)\n",
    "        hw_solver.solve(timeout=1.0)  # Warmup - don't record this time\n",
    "        \n",
    "        # Actual timing runs\n",
    "        times = []\n",
    "        for trial in range(num_trials):\n",
    "            # Set problem data\n",
    "            hw_solver.set_x0(x0_test)\n",
    "            hw_solver.set_x_ref(xref_test)\n",
    "            hw_solver.set_u_ref(uref_test)\n",
    "            \n",
    "            # Measure execution time\n",
    "            start_time = time.perf_counter()\n",
    "            success = hw_solver.solve(timeout=1.0)\n",
    "            end_time = time.perf_counter()\n",
    "            \n",
    "            if success:\n",
    "                exec_time = (end_time - start_time) * 1000  # Convert to ms\n",
    "                times.append(exec_time)\n",
    "        \n",
    "        if len(times) > 0:\n",
    "            results['avg_times'][max_iter] = np.mean(times)\n",
    "            results['all_times'][max_iter] = times\n",
    "    \n",
    "    # Cleanup\n",
    "    hw_solver.cleanup()\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Find all available bitstreams\n",
    "print(\"Searching for bitstream files...\")\n",
    "bitstreams = find_all_bitstreams()\n",
    "\n",
    "if len(bitstreams) == 0:\n",
    "    print(\"No bitstream files found. Looking in current directory and subdirectories...\")\n",
    "    # Try with absolute path\n",
    "    bitstreams = find_all_bitstreams(\"/home/xilinx/jupyter_notebooks/zhenyu/tinympc_ip_gen/\")\n",
    "\n",
    "print(f\"\\nFound {len(bitstreams)} bitstream file(s):\")\n",
    "for idx, bitstream in enumerate(bitstreams):\n",
    "    print(f\"  {idx+1}. {bitstream}\")\n",
    "\n",
    "# Select first bitstream as default if available\n",
    "if len(bitstreams) > 0:\n",
    "    selected_bitstream = bitstreams[0]\n",
    "    print(f\"\\nDefault selected bitstream: {selected_bitstream}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test all bitstreams with max_iter = 10, 100, 1000\n",
    "all_test_results = []\n",
    "test_maxiter_values = [10, 100, 1000]\n",
    "\n",
    "if len(bitstreams) > 0:\n",
    "    print(f\"\\nTesting {len(bitstreams)} bitstream(s) with max_iter values: {test_maxiter_values}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for idx, bitstream in enumerate(bitstreams):\n",
    "        print(f\"\\n[{idx+1}/{len(bitstreams)}] Testing: {bitstream.name}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        try:\n",
    "            # Run performance test with warmup\n",
    "            results = test_bitstream_performance(\n",
    "                bitstream, \n",
    "                test_maxiter_values=test_maxiter_values,\n",
    "                num_trials=10  # 10 trials after warmup for each max_iter\n",
    "            )\n",
    "            \n",
    "            all_test_results.append(results)\n",
    "            \n",
    "            # Display results immediately\n",
    "            print(f\"  N parameter: {results['N']}\")\n",
    "            print(f\"  Average execution times (ms):\")\n",
    "            for max_iter in test_maxiter_values:\n",
    "                if max_iter in results['avg_times']:\n",
    "                    avg_time = results['avg_times'][max_iter]\n",
    "                    std_time = np.std(results['all_times'][max_iter])\n",
    "                    print(f\"    max_iter={max_iter:4d}: {avg_time:8.3f} Â± {std_time:.3f} ms\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"  ERROR: Failed to test bitstream - {e}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"TESTING COMPLETE\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "else:\n",
    "    print(\"No bitstreams found to test.\")\n",
    "\n",
    "# Create summary table of all results\n",
    "if len(all_test_results) > 0:\n",
    "    # Build DataFrame for summary\n",
    "    summary_data = []\n",
    "    for result in all_test_results:\n",
    "        row = {\n",
    "            'Bitstream': Path(result['bitstream']).name,\n",
    "            'N': result['N'],\n",
    "        }\n",
    "        # Add average times for each max_iter value\n",
    "        for max_iter in test_maxiter_values:\n",
    "            if max_iter in result['avg_times']:\n",
    "                row[f'max_iter={max_iter} (ms)'] = f\"{result['avg_times'][max_iter]:.3f}\"\n",
    "            else:\n",
    "                row[f'max_iter={max_iter} (ms)'] = \"N/A\"\n",
    "        summary_data.append(row)\n",
    "    \n",
    "    df_summary = pd.DataFrame(summary_data)\n",
    "    \n",
    "    print(\"\\nSUMMARY TABLE - Average Execution Times\")\n",
    "    print(\"=\" * 80)\n",
    "    print(df_summary.to_string(index=False))\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Export to CSV\n",
    "    csv_filename = 'bitstream_performance_summary.csv'\n",
    "    df_summary.to_csv(csv_filename, index=False)\n",
    "    print(f\"\\nResults exported to: {csv_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bitstream Switch Time Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "all_bitstreams = list(Path(\"bitstream\").glob(\"*.bit\"))\n",
    "\n",
    "# Test bitstream switch time\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BITSTREAM SWITCH TIME TEST\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if len(all_bitstreams) < 2:\n",
    "    print(\"Need at least 2 bitstreams to test switching time\")\n",
    "else:\n",
    "    # Initialize results storage\n",
    "    switch_times = []\n",
    "    \n",
    "    # Number of switches to test\n",
    "    num_tests = 10\n",
    "    \n",
    "    print(f\"Testing {num_tests} switches between bitstreams...\")\n",
    "    \n",
    "    # Alternate between first two bitstreams\n",
    "    for i in range(num_tests):\n",
    "        bitstream = all_bitstreams[i % len(all_bitstreams)]\n",
    "        \n",
    "        # Record start time\n",
    "        start_time = time.time()\n",
    "        new_solver = tinympc_hw(bitstream_path=str(bitstream))\n",
    "        switch_time = (time.time() - start_time) * 1000  # Convert to ms\n",
    "        switch_times.append(switch_time)\n",
    "        print(f\"Switch {i+1}: {switch_time:.2f} ms\")\n",
    "    \n",
    "    # Calculate statistics\n",
    "    avg_switch = np.mean(switch_times)\n",
    "    std_switch = np.std(switch_times)\n",
    "    \n",
    "    print(\"\\nResults:\")\n",
    "    print(f\"Average switch time: {avg_switch:.2f} ms\")\n",
    "    print(f\"Standard deviation: {std_switch:.2f} ms\")\n",
    "    print(\"=\"*60)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
